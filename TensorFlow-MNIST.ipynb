{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow로 MNIST 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이 내용은 [tensorflow tutorial](http://www.tensorflow.org/tutorials/mnist/beginners/index.html)을 바탕으로 작성되었습니다.\n",
    "\n",
    "input_data 모듈을 먼저 받는다. (데이터를 다루기 위해 미리 만들어놓은 python 모듈)\n",
    "\n",
    "    $ wget https://github.com/didw/DL-TF/blob/master/input_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# read mnist data\n",
    "import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist는 60,000개의 mnist.training data와 10,000개의 mnist.test data로 구성되어있다.\n",
    "mnist.train은 image(실제 데이터)와 labels로 구성되어있다.\n",
    "\n",
    "mnist.train.image: 60000 x 784\n",
    "mnist.train.labels: 60000 x 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0~9의 숫자의 확률값을 추출하기 위해 softmax를 사용한다.\n",
    "\n",
    "\n",
    "![softmax-regression](png/softmax-regression-scalargraph.png =500x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.placeholder(\"float\", [None, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x는 어떤 값이 아닌 placeholder이다. (tensorflow가 시작할때 입력값을 넣기 위한 공간을 미리 할당해놓는다 정도로 이해하자.) 값이 None인 것은 임의의 입력 길이를 받기 위함이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W와 b를 정의 & 초기화 한다. Variable은 훈련중에 업데이트되는 tensor이다. 모델 파라메터라고 봐도 되겠다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파라메터를 이용해 모델을 구현한다.\n",
    "\n",
    "\n",
    "![matrix form](png/softmax-regression-vectorequation.png =500x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x,W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "모델을 정의했으니 이제 돌리면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아.. 그 전에 cosftFunction을 정의해야지.\n",
    "여기선 cross entropy를 사용한다.\n",
    "$H_{y'}(y) = -\\sum_i y'_i \\log(y_i)$\n",
    "cross entropy는 y와 y'가 둘다 0이거나 둘다 1이면 값이 작아진다. y'는 레이블이라 당연히 0 또는 1이니, y를 y'과 같은 값을 갖도록 훈련한다고 보면 될 것 같다.\n",
    "머신 러닝을 배울 때 square error를 costFunction으로 계산했던걸 보면 뭔가 더 세련되보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientDescent 방법으로 정의해놓은 costFunction을 줄이도록 훈련방법을 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(\"float\", [None, 10])\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 변수를 초기화하고 세션을 만든 후 돌리면 된다.\n",
    "변수초기화를 다시 하는 이유가 아마도 이전에 0으로 초기화했던걸 무시하고 DBN으로 초기화를 다시 하는게 아닌가 싶다. learning rate: 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련을 할 때 전체 데이터로 훈련하지 않고 100개(1/10)를 랜덤하게 골라서 훈련을 한다. 성능차이는 별로 없고 속도는 당연히 훨씬 빨라진다. 데이터가 많아지니 온갖 꼼수를 다 쓴다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating\n",
    "훈련 했으니 테스트를 해봐야지."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9132\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "print sess.run(accuracy, feed_dict={x: mnist.test.images, y_:mnist.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그냥 \n",
    "\n",
    "    print accuracy\n",
    "하면 안된다.\n",
    "이 문법은 익숙해지는데 시간이 좀 걸릴 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능이 맘에 안든다면 CNN으로.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
